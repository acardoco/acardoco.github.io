---
layout: post
title:  "La familia R-CNN"
date:   2018-08-04 17:26:13 +0200
categories: computer vision and deep learning
---
{:center-image: style="margin: 0 auto; display: block;"}

Las redes convolucionales basadas en regiones (**R-CNN**) se han convertido en unas de las arquitecturas más importantes en detección de objetos, junto a otras procedentes de otros grupos de investigación como *YOLO* o *SSD*.
En la actualidad se han llegado a desarrollar diferentes tipos de *R-CNN*, cada uno más rápido que el anterior pero en general con resultados parecidos.

A continuación se explicará resumidamente las cuatro arquitecturas más conocidas:

El origen de R-CNN 
==================

Hace aproximadamente unos cuatro años apareció la **primera arquitectura** basada en redes convolucionales que resuelve la problemática de buscar objetos dentro de imágenes (*objec-detection*); el grupo de investigadores formado por R. Girshick, J. Donahue, T. Darrell y J. Malik publicó un documento en el que presentaban la idea de redes convolucionales basadas en regiones aplicado al reconocimiento de patrones en la visión por computadora.

El funcionamiento de esta arquitectura es bastante fácil de entender; primero se parte de una red convolucional entrenada para las distintas clases de objetos que se quieren clasificar. Posteriormente, se aplica este modelo ya entrenado en las regiones generadas por un *algoritmo de proposición de zonas de interés* (o *RoI*). Las salidas son procesadas por un SVM (*Support Vector Machine*) y un *regresor lineal* para ajustar los bordes de las zonas propuestas y clasificarlas.

![Arquitectura de una R-CNN.](/figures/r-cnn.png "Arquitectura de una R-CNN."){: center-image}

El problema de este modelo es que para imágenes con un gran tamaño (por ejemplo 1024x1024) el tiempo de ejecución para encontrar objetos en una imágen de prueba suele llegar al minuto ya que por cada región propuesta por el *RoI* (desde 2000 hasta más de 10000) hay que ajustar el tamaño al esperado en la entrada de la *convnet* y ejecutarlo. 

Fast R-CNN
==================

El siguiente tipo de *R-CNN* busca mejorar esos tiempos dándole un nuevo sentido a la aplicación de la *CNN*: en lugar de entrenar con imágenes de solo las clases, esta vez se pasa la imagen completa que contiene las diferentes clases/objetos y se indica con **anotaciones** a la red en qué coordenadas se encuentran estas para que esta red entrene. De esta manera ya no habrá que pasar *n* veces el modelo entrenado en función de las regiones encontradas, mejorando así los tiempos con una duración de ejecución de apenas unos segundos.

![Funcionamiento de Fast R-CNN.](/figures/fast.png "Funcionamiento de Fast R-CNN."){: center-image}

Pero pese a parecer a primera vista mucho mejor que la arquitectura original, sigue existiendo un problema de tiempos a la hora de aplicar el *RoI* en *Fast R-CNN* ya que, aunque solo hay una red convolucional que entrena sobre toda la imágen, se siguen empleando *RoI* en la salida del modelo, cosa que puede generar unos segundos de procesamiento en conjuntos de entrenamiento con imágenes de gran tamaño (con altura y/o anchura superior a 800 píxeles) o clases con muchas características (un coche, una persona, etc).

Faster R-CNN
==================

Para mejorar los tiempos de la anterior arquitectura (concretamente mejorar la duración de los algoritmos de *RoI*) se propuso introducir una red neuronal especial que se encargase de encontrar objetos: una **red de proposición de regiones** (*RPN* las siglas en inglés).

![Funcionamiento de Faster R-CNN.](/figures/faster.png "Funcionamiento de Faster R-CNN."){: center-image}

Esta red se encarga de indicar si hay una alta probabilidad de encontrar algún objeto en *k* cajas de anclaje (*anchor box*), en función del tamaño de la capa y el filtro a aplicar. La información dada por la *RPN* es transmitida al módulo casi similar de la arquitectura de *Fast R-CNN*, el cual que se encargará de clasificar cada región propuesta.

De esta manera, mientras el algoritmo original de redes convolucionales basadas en regiones suele tardar casi un minuto en el proceso de detección de una imagen, *Fast R-CNN* lo reduce a apenas unos segundos y *Faster R-CNN* a unas centésimas de segundo. No obstante, la precisión de todas las arquitectura no difiere mucho unas de otras, como muestra la siguiente figura:

![Comparativa de la familia R-CNN.](/figures/comparativa-rcnn.png "Comparativa de la familia R-CNN."){: center-image}

Mask R-CNN
==================

Hasta ahora se ha hablado de arquitecturas que permiten detectar objetos en imágenes: se dan *n* candidatos con coordenadas y una probabilidad de que ese candidato pertenezca a una de las *k* clases.

La arquitectura de *Mask R-CNN* avanza un nivel más y se introduce en el campo de la **segmentación de instancias/imágenes**: extiende *Faster R-CNN* a nivel de píxel con una *máscara*, por lo que a parte de tener rectángulos de coordenadas y la probabilidad de ser una clase, también indicará en la imágen los píxeles que ocupa uno o más objetos. Segmentación de instancias tiene diferente significado a la **segmetación semántica**, ya que aunque ambos tienen un objetivo similar, la segmentación semántica busca clasificar un segmento mientras la segmentación de imágenes solo indicará en la imagen qué píxeles ocupa ese objeto, sin llegar a decir de qué tipo o a qué clase pertenece.

![Ejemplo de segmentación de imágenes y detección de objetos con Mask R-CNN.](/figures/mask_example.png "Ejemplo de segmentación de imágenes y detección de objetos con Mask R-CNN."){: center-image}